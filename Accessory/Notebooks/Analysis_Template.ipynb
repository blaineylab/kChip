{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Full Pipeline\n",
    "\n",
    "**Inputs**: \n",
    "- config file\n",
    "- image files\n",
    "- well mask file\n",
    "\n",
    "**Outputs**:\n",
    "- droplets DataFrame (csv) \n",
    "- wells DataFrame (csv)\n",
    "- condensed DataFrame (csv)\n",
    "- jupyter notebook pre-loaded with basic quality control plots\n",
    "\n",
    "We have built all the necessary parts in other python notebooks and moved code to kchip_v0 package. Now, implement each step. \n",
    "\n",
    "#### Step 1: Create droplets DataFrame\n",
    "The droplets dataFrame contains information of all droplets in the pre-merge image set. We need to compute and store:\n",
    "- the RGB information of each droplet\n",
    "- the cluster and cluster label of each droplet\n",
    "- the location of each droplet\n",
    "- the well ID of each droplet\n",
    "\n",
    "All of these steps can be found in the \"Putting it together\" notebook. \n",
    "\n",
    "#### Step 2: Create wells DataFrame\n",
    "- Loop through post-merge images and identify wells\n",
    "- Map post-merge wells to pre-merge wells\n",
    "- Condense outputs to final dataframe\n",
    "\n",
    "All of these steps can be found in the \"Registration\" notebook and Final Outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports \n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Append top level directory with kchip package\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# kchip imports\n",
    "import kchip.io as kchip_io\n",
    "import kchip.analyze as kchip_analyze\n",
    "\n",
    "# Other\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in config file\n",
    "with open('config.yml', 'r') as ymlfile:\n",
    "    config = yaml.load(ymlfile)\n",
    "    \n",
    "print yaml.dump(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fontsize = 14\n",
    "plt.rcParams['axes.spines.right']=False\n",
    "plt.rcParams['axes.spines.top']=False\n",
    "\n",
    "plt.rcParams['axes.linewidth']=3\n",
    "plt.rcParams['axes.labelsize']=fontsize\n",
    "plt.rcParams['lines.linewidth']=2\n",
    "plt.rcParams['xtick.labelsize']=fontsize\n",
    "plt.rcParams['ytick.labelsize']=fontsize\n",
    "plt.rcParams['axes.titlesize'] = fontsize\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Helvetica']\n",
    "plt.rcParams['font.size']=fontsize\n",
    "plt.rcParams['xtick.major.width']=1.5\n",
    "plt.rcParams['ytick.major.width']=1.5\n",
    "plt.rcParams['contour.negative_linestyle'] = 'solid'\n",
    "\n",
    "plt.rcParams['savefig.bbox']='Tight'\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create droplets DataFrame\n",
    "- Initialize from images\n",
    "- Identify droplets in the same well from fit to masks\n",
    "- Cluster\n",
    "- Map apriori labels to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize droplets DataFrame from images\n",
    "droplets, rotation_theta = kchip_analyze.initialize_droplets(config)\n",
    "\n",
    "print 'Rotation (degrees): ', rotation_theta*180/np.pi\n",
    "\n",
    "# Identify droplets in the same well from fit to masks\n",
    "droplets = kchip_analyze.fit_droplets_to_mask(config,droplets,rotation_theta)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Identify the clusters (using DBSCAN)\n",
    "droplets = kchip_analyze.identify_clusters(config,droplets,show=1,ax=ax)\n",
    "# Map the cluster centroids to labels\n",
    "droplets = kchip_analyze.map_labels_to_clusters(config,droplets,show=1,ax=ax)\n",
    "\n",
    "print 'Total droplets identified: ', droplets.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create wells DataFrame\n",
    "- Create pre-merge wells dataFrame\n",
    "- Loop through post-merge images and identify wells\n",
    "- Map post-merge wells to pre-merge wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify premerge wells\n",
    "pre_wells = droplets.groupby(['IndexX','IndexY','Well_ID'],as_index=False)[['ImageX','ImageY','Edge']].mean()\n",
    "\n",
    "# List of timepoints\n",
    "timepoints = ['t'+str(i) for i in range(3)]\n",
    "\n",
    "# Analyze data for each timepoint\n",
    "pre_post_all = []\n",
    "for timepoint in timepoints:\n",
    "    print 'Now analyzing timepoint: ', timepoint\n",
    "    # Identify postmerge wells and map to pre-merge wells\n",
    "    pre_post_all.append(kchip_analyze.map_pre_to_post(config,timepoint,pre_wells))\n",
    "    pre_post_all[-1].to_csv(timepoint+'.csv')\n",
    "\n",
    "# Condense output\n",
    "condensed = kchip_analyze.stack_timepoints(droplets,pre_post_all,timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "droplets.to_csv('droplets.csv')\n",
    "condensed.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality control outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chip loading and global well positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_positions = pre_post_all[-1].groupby('Hash').mean()[['Pre_GlobalX','Pre_GlobalY']].values\n",
    "edge = pre_post_all[-1].groupby('Hash').mean()['Pre_Edge'].values\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,10))\n",
    "\n",
    "axes.plot(well_positions[:,0],-well_positions[:,1],'.',ms=2)\n",
    "axes.plot(well_positions[edge,0],-well_positions[edge,1],'.',ms=2)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot by total droplets in well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_count(df,ax):\n",
    "    for item in df['Total'].unique():\n",
    "        pos = df[(df['Total']==item)][['Pre_GlobalX','Pre_GlobalY']].values\n",
    "        ax.plot(pos[:,0],-pos[:,1],'.',ms=2)\n",
    "    return ax\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,10))\n",
    "        \n",
    "condensed[['Hash','Total','t2_Area']] \\\n",
    "    .merge(pre_post_all[-1][['Hash','Pre_GlobalX','Pre_GlobalY','Pre_Edge']],on='Hash') \\\n",
    "    .pipe(plot_by_count,ax=axes) \n",
    "    \n",
    "axes.legend(condensed['Total'].unique(),loc=2,bbox_to_anchor=(1.05,1))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot area over chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "data = condensed[['Hash','Total','t2_Area']] \\\n",
    "    .merge(pre_post_all[-1][['Hash','Pre_GlobalX','Pre_GlobalY','Pre_Edge']],on='Hash') \n",
    "\n",
    "width = 1e1\n",
    "bins = np.arange(0,2e3,width)\n",
    "\n",
    "bin_by_area = pd.cut(data['t2_Area'],bins)\n",
    "bin_label = dict([(item,i) for i, item in enumerate(bin_by_area.unique().sort_values())])\n",
    "\n",
    "data['Area_Bin']=[bin_label[item] for item in bin_by_area]\n",
    "\n",
    "cmap = colors.LinearSegmentedColormap.from_list('', ['green','yellow','red','violet'],N=data['Area_Bin'].max())\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(20,10))\n",
    "axes[0].scatter(data['Pre_GlobalX'],-data['Pre_GlobalY'],c=data['Area_Bin'],cmap=cmap,marker='.',s=10,alpha=1)\n",
    "axes[0].axis('off')\n",
    "\n",
    "invert_label = {v: k for k, v in bin_label.iteritems()}\n",
    "\n",
    "for label in invert_label.keys():\n",
    "    if invert_label[label]==invert_label[label]:\n",
    "        axes[1].bar(invert_label[label].mid,(data['Area_Bin']==label).sum(),width=width,color=cmap(label))\n",
    "\n",
    "axes[1].set_xlabel('Area')\n",
    "axes[1].set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "p = sns.pointplot(data=droplets.groupby('Label').count().reset_index(),x='Label',y='RX',join=False)\n",
    "\n",
    "p.set_xticklabels(p.get_xticklabels(),rotation=90)\n",
    "p.set_ylim([0,droplets.groupby('Label').count()['RX'].max()*1.5]);\n",
    "p.set_ylabel('Count')\n",
    "p.set_title('Representation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms of GFP and Area values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = condensed.filter(regex='t\\d+(?!_)').columns.values\n",
    "\n",
    "fig, axes = plt.subplots(1,len(timepoints),figsize=(4*len(timepoints),4))\n",
    "\n",
    "bins = np.arange(0,1e4,1e2)\n",
    "\n",
    "for ax, t in zip(axes,timepoints):\n",
    "    ax.hist(condensed[t].dropna(),bins=bins)\n",
    "    ax.set_xlabel('GFP Fluorescence')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_title('Signal at '+t)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = condensed.filter(regex='t\\d+_Area').columns.values\n",
    "\n",
    "fig, axes = plt.subplots(1,len(timepoints),figsize=(4*len(timepoints),4))\n",
    "\n",
    "bins = np.arange(0,2e3,1e1)\n",
    "\n",
    "for ax, t in zip(axes,timepoints):\n",
    "    ax.hist(condensed[t].dropna(),bins=bins)\n",
    "    ax.set_xlabel('Area')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_title('Area at '+t[:-5])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
